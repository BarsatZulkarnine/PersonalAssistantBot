# Application Settings
app:
  name: "Voice Assistant"
  version: "3.0.0"
  debug: true

# Speech Recognition
speech:
  hotword: "hey jarvis"
  listen_timeout: 5
  phrase_time_limit: 10
  language: "en"

# Text-to-Speech
tts:
  provider: "gtts"  # Options: gtts, elevenlabs, piper, azure, openai_tts
  language: "en"
  speed: 1.0
  pitch: 1.0
  voice: null
  streaming: true

# AI Configuration
ai:
  provider: "openai"
  model: "gpt-4o-mini"
  temperature: 0.7
  max_tokens: 500

# Intent Classification
intent:
  confidence_threshold: 0.7
  fallback_to_ai: true

# ============================================
# I/O Configuration (NEW - Phase 2)
# ============================================
io:
  # Input mode: auto, microphone, keyboard, websocket (future)
  input: auto
  
  # Output mode: auto, speaker, console, websocket (future)
  output: auto
  
  # Fallback behavior
  fallback:
    enabled: true           # Auto-fallback if hardware unavailable
    input_order:            # Try in this order
      - microphone
      - keyboard
    output_order:
      - speaker
      - console
  
  # Hardware requirements
  requirements:
    microphone_required: false   # Exit if mic required but unavailable
    speaker_required: false      # Exit if speaker required but unavailable

# Security
security:
  require_confirmation:
    - send_email
    - delete_file
    - system_command
  require_auth:
    - payment
    - sensitive_data

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  file: "logs/assistant.log"
  max_size_mb: 10
  backup_count: 5
  log_conversations: true

# Performance
performance:
  cache_responses: true
  cache_ttl_seconds: 3600
  parallel_execution: false